{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignmant7e.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPirmdumZpRV6WNZO4nxh5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/95871abhinandankumar/95871abhinandankumar/blob/main/assignmant7e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFW5ceW_r9Jc"
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qin5lgNsDC2",
        "outputId": "4848a210-4e76-43de-97fe-d3470c7a8746"
      },
      "source": [
        "print(\"target name\")\n",
        "print(iris.target_names)\n",
        "print(\"target...\")\n",
        "iris.target"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target name\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "target...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6gz7xtQtOW3",
        "outputId": "8337d6f6-3597-4417-825f-a50c8cde3cdd"
      },
      "source": [
        "df = pd.DataFrame(iris.data,columns=[iris.feature_names])\n",
        "df['target'] = iris.target\n",
        "\n",
        "print(df)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    sepal length (cm) sepal width (cm)  ... petal width (cm) target\n",
            "0                 5.1              3.5  ...              0.2      0\n",
            "1                 4.9              3.0  ...              0.2      0\n",
            "2                 4.7              3.2  ...              0.2      0\n",
            "3                 4.6              3.1  ...              0.2      0\n",
            "4                 5.0              3.6  ...              0.2      0\n",
            "..                ...              ...  ...              ...    ...\n",
            "145               6.7              3.0  ...              2.3      2\n",
            "146               6.3              2.5  ...              1.9      2\n",
            "147               6.5              3.0  ...              2.0      2\n",
            "148               6.2              3.4  ...              2.3      2\n",
            "149               5.9              3.0  ...              1.8      2\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8bpNaHqtBL_",
        "outputId": "077321fe-773f-476f-df69-382f56f16fe6"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaling = MinMaxScaler()\n",
        "samples = scaling.fit_transform(df[df.columns])\n",
        "df = pd.DataFrame(samples)\n",
        "\n",
        "print(df)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            0         1         2         3    4\n",
            "0    0.222222  0.625000  0.067797  0.041667  0.0\n",
            "1    0.166667  0.416667  0.067797  0.041667  0.0\n",
            "2    0.111111  0.500000  0.050847  0.041667  0.0\n",
            "3    0.083333  0.458333  0.084746  0.041667  0.0\n",
            "4    0.194444  0.666667  0.067797  0.041667  0.0\n",
            "..        ...       ...       ...       ...  ...\n",
            "145  0.666667  0.416667  0.711864  0.916667  1.0\n",
            "146  0.555556  0.208333  0.677966  0.750000  1.0\n",
            "147  0.611111  0.416667  0.711864  0.791667  1.0\n",
            "148  0.527778  0.583333  0.745763  0.916667  1.0\n",
            "149  0.444444  0.416667  0.694915  0.708333  1.0\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql4sRmDnuBox"
      },
      "source": [
        "def hypothesis(w,dataset):\n",
        "  y=w[0]\n",
        "  sample =dataset[:-1]\n",
        "  sample = np.concatenate([[1], sample])\n",
        "  y = np.multiply(w, sample)\n",
        "  y = np.sum(y)\n",
        "  gx = 1/(1+(math.e)**(-1*y))\n",
        "  return gx"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E-Ze6xSuFzT",
        "outputId": "7f480664-20fd-46cd-f4ae-adb9346561af"
      },
      "source": [
        "def predicted_values(w, dataset):\n",
        "  predicted = []\n",
        "  for i in range(len(dataset)):\n",
        "    predicted.append(hypothesis(w, dataset[i]))\n",
        "  \n",
        "  return np.array(predicted)\n",
        "\n",
        "\n",
        "# to calculate mean square error\n",
        "def MSE(predicted, actual):\n",
        "  return np.square(np.subtract(predicted, actual)).mean()/2\n",
        "\n",
        "print(MSE(np.array([1,2,3,4]), np.array([1,2,3,4]),))\n",
        "\n",
        "\n",
        "def accurracy(predicted, actual):\n",
        "  tp = 0\n",
        "  tn = 0\n",
        "  fp = 0\n",
        "  fn = 0\n",
        "  for i in range(len(predicted)):\n",
        "    if predicted[i] >= 0.5 and actual[i] == 1:\n",
        "      tp += 1\n",
        "    elif predicted[i] >= 0.5 and actual[i] == 0:\n",
        "      fp += 1\n",
        "    elif predicted[i] <= 0.5 and actual[i] == 0:\n",
        "      tn += 1\n",
        "    elif predicted[i] <= 0.5 and actual[i] == 0:\n",
        "      fn += 1\n",
        "  return tp, tn, fp, fn"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNpZPCJMuLlv"
      },
      "source": [
        "# to update w using stochastic gradient decendent\n",
        "def update_parameter_stochastic(w, alpha, dataset):\n",
        "  np.random.shuffle(dataset)\n",
        "  m = len(dataset)\n",
        "  for j in range(m):\n",
        "    hy = hypothesis(w, np.array(dataset[j]))\n",
        "    w[0] = w[0] - (alpha /m)*(hy- dataset[:, -1][j])\n",
        "    for i in range(1, len(w)):\n",
        "      w[i] = w[i] - (alpha /m)*((hy- dataset[:, -1][j])* dataset[:, i-1][j])\n",
        "  return w"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CQLzrbSuOkz"
      },
      "source": [
        "def logistic_regression(epoch, alpha, rho, w, train_dataset):\n",
        "  pre_MSE = 0\n",
        "  curr_MSE = 0\n",
        "  trains_MSE=[]\n",
        "  for itr in range(epoch):\n",
        "    predicted = predicted_values(w, train_dataset)\n",
        "    curr_MSE = MSE(predicted, train_dataset[:,-1])\n",
        "    w = update_parameter_stochastic(w, alpha, train_dataset)\n",
        "    \n",
        "    trains_MSE.append(curr_MSE)\n",
        "\n",
        "    if abs(curr_MSE - pre_MSE) <= rho:\n",
        "      break;\n",
        "    pre_MSE = curr_MSE\n",
        "  return w, trains_MSE"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ujICafYuh40"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils.testing import ignore_warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chxj5yYzvE7Z",
        "outputId": "f501e9ae-e1f2-41f2-af33-fe1075f0ecde"
      },
      "source": [
        "dataset = df.to_numpy()\n",
        "kf = KFold(n_splits=5,shuffle=True)\n",
        "w_versicolor = [1,1,1,1,1]\n",
        "w_verginica = [1,1,1,1,1]\n",
        "w_setosa = [1,1,1,1,1]\n",
        "\n",
        "for train_index, test_index in kf.split(dataset):\n",
        "  print(\"  ..............................  \")\n",
        "  train = []\n",
        "  test = []\n",
        "  for i in train_index :\n",
        "    train.append(dataset[i])\n",
        "\n",
        "  for i in test_index :\n",
        "    test.append(dataset[i])\n",
        "\n",
        "\n",
        "  train_setosa = np.copy(train)\n",
        "\n",
        "  for i in range(len(train_setosa)):\n",
        "    if train_setosa[i][-1] == 0:\n",
        "      train_setosa[i][-1] = 1\n",
        "    else:\n",
        "      train_setosa[i][-1] = 0\n",
        "  \n",
        "  test_setosa = np.copy(test)\n",
        "\n",
        "  for i in range(len(test_setosa)):\n",
        "    if test_setosa[i][-1] == 0:\n",
        "      test_setosa[i][-1] = 1\n",
        "    else:\n",
        "      test_setosa[i][-1] = 0\n",
        "\n",
        "  train_versicolor = np.copy(train)\n",
        "\n",
        "  for i in range(len(train_versicolor)):\n",
        "    if train_versicolor[i][-1] == 0.5:\n",
        "      train_versicolor[i][-1] = 1\n",
        "    else:\n",
        "      train_versicolor[i][-1] = 0\n",
        "  \n",
        "  test_versicolor = np.copy(test)\n",
        "\n",
        "  for i in range(len(test_versicolor)):\n",
        "    if test_versicolor[i][-1] == 0.5:\n",
        "      test_versicolor[i][-1] = 1\n",
        "    else:\n",
        "      test_versicolor[i][-1] = 0\n",
        "\n",
        "  train_verginica = np.copy(train)\n",
        "\n",
        "  for i in range(len(train_verginica)):\n",
        "    if train_verginica[i][-1] != 1:\n",
        "      train_verginica[i][-1] = 0\n",
        "\n",
        "\n",
        "  test_verginica = np.copy(test)\n",
        "\n",
        "  for i in range(len(test_verginica)):\n",
        "    if test_verginica[i][-1] != 1:\n",
        "      test_verginica[i][-1] = 0\n",
        "\n",
        "  print(\"class wise accurracy  for setosa \")\n",
        "  w_setosa, st_mse= logistic_regression(7, i, 0.1, w_setosa, train_setosa)\n",
        "  predicted = predicted_values(w_setosa, train_setosa)\n",
        "  tp, tn, fp, fn = accurracy(predicted, train_setosa[:,-1])\n",
        "  print(\"train accurracy of setosa\", (tp + tn )/len(train_setosa))\n",
        "  print(\"precison \" , tp/len(train_setosa))\n",
        "  print(\"recall \", tp/len(train_setosa))\n",
        "  predicted = predicted_values(w_setosa, test_setosa)\n",
        "  tp, tn, fp, fn = accurracy(predicted, test_setosa[:,-1])\n",
        "  tp_st = tp\n",
        "  print(\"test accurracy of setosa\", (tp + tn )/len(test_setosa))\n",
        "  print(\"precison \" , tp/len(train_setosa))\n",
        "  print(\"recall \", tp/len(train_setosa))\n",
        "\n",
        "  w_versicolor, st_mse= logistic_regression(7, i, 0.1, w_versicolor, train_versicolor)\n",
        "  predicted = predicted_values(w_versicolor, train_versicolor)\n",
        "  tp, tn, fp, fn = accurracy(predicted, train_versicolor[:,-1])\n",
        "  print(\"train accurracy of versicolor\", (tp + tn )/len(train_versicolor))\n",
        "  print(\"precison \" , tp/len(train_versicolor))\n",
        "  print(\"recall \", tp/len(train_versicolor))\n",
        "  predicted = predicted_values(w_versicolor, test_versicolor)\n",
        "  tp, tn, fp, fn = accurracy(predicted, test_versicolor[:,-1])\n",
        "  print(\"test accurracy of versicolor\", (tp + tn )/len(test_versicolor))\n",
        "  print(\"precison \" , tp/len(train_versicolor))\n",
        "  print(\"recall \", tp/len(train_versicolor))\n",
        "  tp_tv = tp\n",
        "\n",
        "  w_verginica, st_mse= logistic_regression(7, i, 0.1, w_verginica, train_verginica)\n",
        "  predicted = predicted_values(w_verginica, train_verginica)\n",
        "  tp, tn, fp, fn = accurracy(predicted, train_verginica[:,-1])\n",
        "  print(\"train accurracy of verginica\", (tp + tn )/len(train_verginica))\n",
        "  print(\"precison \" , tp/len(train_verginica))\n",
        "  print(\"recall \", tp/len(train_verginica))\n",
        "  predicted = predicted_values(w_verginica, test_verginica)\n",
        "  tp, tn, fp, fn = accurracy(predicted, test_verginica[:,-1])\n",
        "  print(\"test accurracy of verginica\", (tp + tn )/len(test_verginica))\n",
        "  print(\"precison \" , tp/len(train_verginica))\n",
        "  print(\"recall \", tp/(len(train_verginica)))\n",
        "  tp_vt = tp\n",
        "\n",
        "  print(\"overall accuraccy : \", (tp_st + tp_tv + tp_vt)/(len(test)))\n",
        "    \n",
        "  "
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ..............................  \n",
            "class wise accurracy  for setosa \n",
            "train accurracy of setosa 1.0\n",
            "precison  0.325\n",
            "recall  0.325\n",
            "test accurracy of setosa 1.0\n",
            "precison  0.09166666666666666\n",
            "recall  0.09166666666666666\n",
            "train accurracy of versicolor 0.6333333333333333\n",
            "precison  0.1\n",
            "recall  0.1\n",
            "test accurracy of versicolor 0.6666666666666666\n",
            "precison  0.016666666666666666\n",
            "recall  0.016666666666666666\n",
            "train accurracy of verginica 0.9666666666666667\n",
            "precison  0.30833333333333335\n",
            "recall  0.30833333333333335\n",
            "test accurracy of verginica 1.0\n",
            "precison  0.09166666666666666\n",
            "recall  0.09166666666666666\n",
            "overall accuraccy :  0.8\n",
            "  ..............................  \n",
            "class wise accurracy  for setosa \n",
            "train accurracy of setosa 1.0\n",
            "precison  0.375\n",
            "recall  0.375\n",
            "test accurracy of setosa 1.0\n",
            "precison  0.041666666666666664\n",
            "recall  0.041666666666666664\n",
            "train accurracy of versicolor 0.675\n",
            "precison  0.03333333333333333\n",
            "recall  0.03333333333333333\n",
            "test accurracy of versicolor 0.6\n",
            "precison  0.016666666666666666\n",
            "recall  0.016666666666666666\n",
            "train accurracy of verginica 0.925\n",
            "precison  0.3\n",
            "recall  0.3\n",
            "test accurracy of verginica 0.9\n",
            "precison  0.10833333333333334\n",
            "recall  0.10833333333333334\n",
            "overall accuraccy :  0.6666666666666666\n",
            "  ..............................  \n",
            "class wise accurracy  for setosa \n",
            "train accurracy of setosa 1.0\n",
            "precison  0.3\n",
            "recall  0.3\n",
            "test accurracy of setosa 1.0\n",
            "precison  0.11666666666666667\n",
            "recall  0.11666666666666667\n",
            "train accurracy of versicolor 0.6583333333333333\n",
            "precison  0.18333333333333332\n",
            "recall  0.18333333333333332\n",
            "test accurracy of versicolor 0.6666666666666666\n",
            "precison  0.016666666666666666\n",
            "recall  0.016666666666666666\n",
            "train accurracy of verginica 0.9583333333333334\n",
            "precison  0.3416666666666667\n",
            "recall  0.3416666666666667\n",
            "test accurracy of verginica 0.9666666666666667\n",
            "precison  0.06666666666666667\n",
            "recall  0.06666666666666667\n",
            "overall accuraccy :  0.8\n",
            "  ..............................  \n",
            "class wise accurracy  for setosa \n",
            "train accurracy of setosa 1.0\n",
            "precison  0.3333333333333333\n",
            "recall  0.3333333333333333\n",
            "test accurracy of setosa 1.0\n",
            "precison  0.08333333333333333\n",
            "recall  0.08333333333333333\n",
            "train accurracy of versicolor 0.7\n",
            "precison  0.05\n",
            "recall  0.05\n",
            "test accurracy of versicolor 0.7\n",
            "precison  0.025\n",
            "recall  0.025\n",
            "train accurracy of verginica 0.9333333333333333\n",
            "precison  0.35\n",
            "recall  0.35\n",
            "test accurracy of verginica 0.9\n",
            "precison  0.06666666666666667\n",
            "recall  0.06666666666666667\n",
            "overall accuraccy :  0.7\n",
            "  ..............................  \n",
            "class wise accurracy  for setosa \n",
            "train accurracy of setosa 1.0\n",
            "precison  0.3333333333333333\n",
            "recall  0.3333333333333333\n",
            "test accurracy of setosa 1.0\n",
            "precison  0.08333333333333333\n",
            "recall  0.08333333333333333\n",
            "train accurracy of versicolor 0.7\n",
            "precison  0.16666666666666666\n",
            "recall  0.16666666666666666\n",
            "test accurracy of versicolor 0.6333333333333333\n",
            "precison  0.041666666666666664\n",
            "recall  0.041666666666666664\n",
            "train accurracy of verginica 0.95\n",
            "precison  0.3\n",
            "recall  0.3\n",
            "test accurracy of verginica 0.9333333333333333\n",
            "precison  0.058333333333333334\n",
            "recall  0.058333333333333334\n",
            "overall accuraccy :  0.7333333333333333\n"
          ]
        }
      ]
    }
  ]
}