{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_multiclass_classification_lab6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM0nCXEU2lnSCN+sJtRrC2G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/95871abhinandankumar/95871abhinandankumar/blob/main/ML_multiclass_classification_lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jljjhsKhhuIS"
      },
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9Db8yYNiAJe",
        "outputId": "9bfacb48-053f-4d56-ef40-ecdbbeab9e9b"
      },
      "source": [
        "# features of iris dataset\n",
        "iris.feature_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4DRcOu7iHt_",
        "outputId": "07d03874-45d6-4206-f313-739e4c341b81"
      },
      "source": [
        "print(\"target name\")\n",
        "print(iris.target_names)\n",
        "print(\"target...\")\n",
        "iris.target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target name\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "target...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bux84YJviiXH",
        "outputId": "3f28595b-c76e-458b-943e-d1aa2e0960c3"
      },
      "source": [
        "df = pd.DataFrame(iris.data,columns=[iris.feature_names])\n",
        "df['target'] = iris.target\n",
        "\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    sepal length (cm) sepal width (cm)  ... petal width (cm) target\n",
            "0                 5.1              3.5  ...              0.2      0\n",
            "1                 4.9              3.0  ...              0.2      0\n",
            "2                 4.7              3.2  ...              0.2      0\n",
            "3                 4.6              3.1  ...              0.2      0\n",
            "4                 5.0              3.6  ...              0.2      0\n",
            "..                ...              ...  ...              ...    ...\n",
            "145               6.7              3.0  ...              2.3      2\n",
            "146               6.3              2.5  ...              1.9      2\n",
            "147               6.5              3.0  ...              2.0      2\n",
            "148               6.2              3.4  ...              2.3      2\n",
            "149               5.9              3.0  ...              1.8      2\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq7jDk1UiQ01",
        "outputId": "2093048d-797c-4187-d5d1-c470b6ee1dc9"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaling = MinMaxScaler()\n",
        "samples = scaling.fit_transform(df[df.columns])\n",
        "df = pd.DataFrame(samples)\n",
        "\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            0         1         2         3    4\n",
            "0    0.222222  0.625000  0.067797  0.041667  0.0\n",
            "1    0.166667  0.416667  0.067797  0.041667  0.0\n",
            "2    0.111111  0.500000  0.050847  0.041667  0.0\n",
            "3    0.083333  0.458333  0.084746  0.041667  0.0\n",
            "4    0.194444  0.666667  0.067797  0.041667  0.0\n",
            "..        ...       ...       ...       ...  ...\n",
            "145  0.666667  0.416667  0.711864  0.916667  1.0\n",
            "146  0.555556  0.208333  0.677966  0.750000  1.0\n",
            "147  0.611111  0.416667  0.711864  0.791667  1.0\n",
            "148  0.527778  0.583333  0.745763  0.916667  1.0\n",
            "149  0.444444  0.416667  0.694915  0.708333  1.0\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00VM-PJlmWhn"
      },
      "source": [
        "dataset = df.to_numpy()\n",
        "# print(dataset)\n",
        "\n",
        "dataset_setosa = np.copy(dataset)\n",
        "\n",
        "for i in range(len(dataset_setosa)):\n",
        "  if dataset_setosa[i][-1] == 0:\n",
        "    dataset_setosa[i][-1] = 1\n",
        "  else:\n",
        "    dataset_setosa[i][-1] = 0\n",
        "\n",
        "# print(dataset_setosa)\n",
        "# print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT_p9WHIoVfz"
      },
      "source": [
        "dataset_versicolor = np.copy(dataset)\n",
        "\n",
        "for i in range(len(dataset_versicolor)):\n",
        "  if dataset_versicolor[i][-1] == 0.5:\n",
        "    dataset_versicolor[i][-1] = 1\n",
        "  else:\n",
        "    dataset_versicolor[i][-1] = 0\n",
        "# print(dataset)\n",
        "# print(dataset_versicolor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XlZ98Dco3qU"
      },
      "source": [
        "dataset_verginica = np.copy(dataset)\n",
        "\n",
        "for i in range(len(dataset_verginica)):\n",
        "  if dataset_verginica[i][-1] != 1:\n",
        "    dataset_verginica[i][-1] = 0\n",
        "print(dataset_verginica)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bxArielqYZD"
      },
      "source": [
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf6SlB0Sqj3-"
      },
      "source": [
        "def hypothesis(w,x):\n",
        "  y=w[0]\n",
        "  sample =dataset[:-1]\n",
        "  sample = np.concatenate([[1], sample])\n",
        "  y = np.multiply(w, sample)\n",
        "  gx = 1/(1+(math.e)**(-1*y))\n",
        "  return gx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWi99thEsRtu"
      },
      "source": [
        "# to calculate the predicted value with the help of hypothesis function\n",
        "def predicted_values(w, dataset):\n",
        "  predicted = []\n",
        "  for i in range(len(dataset)):\n",
        "    predicted.append(hypothesis(w, dataset[i]))\n",
        "  \n",
        "  return np.array(predicted)\n",
        "\n",
        "\n",
        "# to calculate mean square error\n",
        "def MSE(predicted, actual):\n",
        "  return np.square(np.subtract(predicted, actual)).mean()/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF0MGNuetUF-"
      },
      "source": [
        "# log function\n",
        "\n",
        "\n",
        "# log loss function\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hZjR0zYw6jb"
      },
      "source": [
        "# to update w using stochastic gradient decendent\n",
        "def update_parameter_stochastic(w, alpha, dataset):\n",
        "  np.random.shuffle(dataset)\n",
        "  m = len(dataset)\n",
        "  for j in range(m):\n",
        "    hy = hypothesis(w, j, dataset)\n",
        "    w[0] = w[0] - (alpha /m)*(hy- dataset[:, -1][j])\n",
        "    for i in range(1, len(w)):\n",
        "      w[i] = w[i] - (alpha /m)*((hy- dataset[:, -1][j])* dataset[:, i-1][j])\n",
        "  return w\n",
        "print(update_parameter_stochastic([1,1,1], 0.1, dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0oM1fp1wAvh"
      },
      "source": [
        "def logistic_regression(epoch, alpha, rho, w, train_dataset, validation):\n",
        "  pre_MSE = 0\n",
        "  curr_MSE = 0\n",
        "  trains_MSE=[]\n",
        "  validations_MSE=[]\n",
        "  for itr in range(epoch):\n",
        "    predicted = predicted_values(w, train_dataset)\n",
        "    curr_MSE = MSE(predicted, train_dataset[:,-1])\n",
        "    w = update_parameter(w, alpha, train_dataset)\n",
        "    \n",
        "    trains_MSE.append(curr_MSE)\n",
        "    predicted = predicted_values(w, validation)\n",
        "    validations_MSE.append(MSE(predicted, validation[:,-1]))\n",
        "\n",
        "    if abs(curr_MSE - pre_MSE) <= rho:\n",
        "      break;\n",
        "    pre_MSE = curr_MSE\n",
        "  return w, trains_MSE, validations_MSE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}